{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccessary libraries that may be useful\n",
    "\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gordo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gordo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import language processing functions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data importing\n",
    "\n",
    "all_data = []\n",
    "csv_dir = './YouTube-Spam-Collection-v1/'\n",
    "csv_files = ['Youtube01-Psy.csv','Youtube02-KatyPerry.csv','Youtube03-LMFAO.csv','Youtube04-Eminem.csv','Youtube05-Shakira.csv']\n",
    "\n",
    "for file in csv_files:\n",
    "    data = pd.read_csv(csv_dir + file)\n",
    "    all_data.append(data)\n",
    "all_data = pd.concat(all_data)\n",
    "\n",
    "# Sanity checkpoint\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1005\n",
       "0     951\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data imbalance check (no issue here)\n",
    "all_data['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  CLASS\n",
       "0  Huh, anyway check out this you[tube] channel: ...      1\n",
       "1  Hey guys check out my new channel and our firs...      1\n",
       "2             just for test I have to say murdev.com      1\n",
       "3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1\n",
       "4            watch?v=vtaRGgvGtWQ   Check this out .﻿      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing / cleaning\n",
    "\n",
    "# Only keep Comment content and Class label\n",
    "all_data.drop(['COMMENT_ID','AUTHOR','DATE'], axis=1, inplace=True, errors='ignore')\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing / cleaning\n",
    "def process_content(comment):\n",
    "    edited_comment = \" \".join(re.findall(\"[A-Za-z]+\", comment.lower()))\n",
    "    edited_comment = edited_comment.replace('\\ufeff', '')\n",
    "    edited_comment = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\",'http', edited_comment)\n",
    "    return edited_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>PROCESSED CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>huh anyway check out this you tube channel kob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey guys check out my new channel and our firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "      <td>just for test i have to say murdev com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>watch v vtarggvgtwq check this out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  CLASS  \\\n",
       "0  Huh, anyway check out this you[tube] channel: ...      1   \n",
       "1  Hey guys check out my new channel and our firs...      1   \n",
       "2             just for test I have to say murdev.com      1   \n",
       "3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1   \n",
       "4            watch?v=vtaRGgvGtWQ   Check this out .﻿      1   \n",
       "\n",
       "                                   PROCESSED CONTENT  \n",
       "0  huh anyway check out this you tube channel kob...  \n",
       "1  hey guys check out my new channel and our firs...  \n",
       "2             just for test i have to say murdev com  \n",
       "3         me shaking my sexy ass on my channel enjoy  \n",
       "4                 watch v vtarggvgtwq check this out  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['PROCESSED CONTENT'] = all_data['CONTENT'].apply(process_content)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413                        me and my big sister like you\n",
      "187    who else would give katy perry a good old migh...\n",
      "39     its a good song and i like her video clip beca...\n",
      "294                  i ll subscribe to you you look nice\n",
      "428                            watch this with sound off\n",
      "                             ...                        \n",
      "89     http www aaas org tech i vote view vote sheldo...\n",
      "40                                           watching in\n",
      "269    when i hear katy singing this i cry the song h...\n",
      "89     check out the new hot video by dante b called ...\n",
      "378                                            subscribe\n",
      "Name: PROCESSED CONTENT, Length: 1564, dtype: object\n",
      "413    0\n",
      "187    0\n",
      "39     0\n",
      "294    1\n",
      "428    0\n",
      "      ..\n",
      "89     1\n",
      "40     0\n",
      "269    0\n",
      "89     1\n",
      "378    1\n",
      "Name: CLASS, Length: 1564, dtype: int64\n",
      "x_train.shape = (1564,)\n",
      "x_test.shape = (392,)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_data['PROCESSED CONTENT'],all_data['CLASS'], test_size=0.2, random_state=69)\n",
    "\n",
    "# Sanity checkpoint\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "# Print the shape train and test sets\n",
    "print(\"x_train.shape = \" + str(x_train.shape))\n",
    "print(\"x_test.shape = \" + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using Counter Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_test_counts = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency - inverse document frequency\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tranformer = TfidfTransformer()\n",
    "x_train_tfidf = tranformer.fit_transform(x_train_counts)\n",
    "x_test_tfidf = tranformer.transform(x_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9540816326530612\n"
     ]
    }
   ],
   "source": [
    "# Create and train Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(x_train_tfidf, y_train)\n",
    "\n",
    "accuracy = model_LR.score(x_test_tfidf, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "# Create and train Random Forest Classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_RFC = RandomForestClassifier()\n",
    "model_RFC.fit(x_train_tfidf,y_train)\n",
    "\n",
    "accuracy = model_RFC.score(x_test_tfidf, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "# Create and train Multi-Layer Perceptron model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_NN = MLPClassifier(hidden_layer_sizes=(20,40,40,20), activation='relu', solver='adam', max_iter=10000)\n",
    "model_NN.fit(x_train_tfidf, y_train)\n",
    "\n",
    "accuracy = model_NN.score(x_test_tfidf, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gordo\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.923469387755102\n"
     ]
    }
   ],
   "source": [
    "# Create and train XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_XGB = XGBClassifier(objective = 'binary:logistic', max_depth = 4, alpha = 10, learning_rate = 1.0, n_estimators = 100)\n",
    "model_XGB.fit(x_train_tfidf, y_train)\n",
    "\n",
    "accuracy = model_XGB.score(x_test_tfidf, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'n_estimators': 120}\n",
      "0.9642857142857143\n"
     ]
    }
   ],
   "source": [
    "# To improve, can use Grid Search to find best parameters\n",
    "\n",
    "# Try Grid Search with Random Forest Classifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "                'n_estimators': [80, 100, 120],\n",
    "                'bootstrap': [True, False],\n",
    "                'criterion' : ['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "model_RFC_GSCV = GridSearchCV(RandomForestClassifier(), parameters)\n",
    "model_RFC_GSCV.fit(x_train_tfidf, y_train)\n",
    "\n",
    "print(model_RFC_GSCV.best_params_)\n",
    "\n",
    "accuracy = model_RFC_GSCV.score(x_test_tfidf, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, let's try Naive Bayes method.\n",
    "\n",
    "stopwords_english = stopwords.words('english') \n",
    "stemmer = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(result, comments, ys):\n",
    "    '''\n",
    "    Input:\n",
    "        result: a dictionary that will be used to map each pair to its frequency\n",
    "        tweets: a list of comments\n",
    "        ys: a list corresponding to the class of each comment (either 0 or 1)\n",
    "    Output:\n",
    "        result: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    for y, comment in zip(ys, comments):\n",
    "        comment_tokens = word_tokenize(process_content(comment))\n",
    "        \n",
    "        comment_stem = []\n",
    "\n",
    "        for word in comment_tokens: # Go through every word in your tokens list\n",
    "            if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "                \n",
    "                stem_word = stemmer.stem(word)  # stemming word\n",
    "                comment_stem.append(stem_word)  # append to the list\n",
    "                \n",
    "        for word in comment_stem:\n",
    "            # define the key, which is the word and label tuple\n",
    "            pair = (word, y)\n",
    "            \n",
    "            # if the key exists in the dictionary, increment the count\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the freqs dictionary for later uses\n",
    "\n",
    "freqs = count_tweets({}, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of tweets\n",
    "        train_y: a list of labels correponding to the comments (0,1)\n",
    "    Output:\n",
    "        logprior: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculate N_pos, N_neg, V_pos, V_neg\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        # if the label is positive (greater than zero)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Increment the number of positive words by the count for this (word, label) pair\n",
    "            N_pos += freqs.get(pair, 1)\n",
    "\n",
    "        # else, the label is negative\n",
    "        else:\n",
    "\n",
    "            # increment the number of negative words by the count for this (word,label) pair\n",
    "            N_neg += freqs.get(pair, 1)\n",
    "    \n",
    "    # Calculate D, the number of documents\n",
    "    D = len(train_y)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents\n",
    "    D_pos = sum(train_y)\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents\n",
    "    D_neg = D - D_pos\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(D_pos) - np.log(D_neg)\n",
    "    \n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab:\n",
    "        # get the positive and negative frequency of the word\n",
    "        freq_pos = freqs.get((word, 1.0), 0)\n",
    "        freq_neg = freqs.get((word, 0.0), 0)\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos) - np.log(p_w_neg)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(comment, logprior, loglikelihood):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Output:\n",
    "        p: the sum of all the logliklihoods of each word in the comment (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    ### START CODE HERE ###\n",
    "    # process the tweet to get a list of words\n",
    "    word_l = word_tokenize(process_content(comment))\n",
    "\n",
    "    # initialize probability to zero\n",
    "    p = 0\n",
    "\n",
    "    # add the logprior\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(x_test, y_test, logprior, loglikelihood, naive_bayes_predict=naive_bayes_predict):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of tweets\n",
    "        test_y: the corresponding labels for the list of comments\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of comments classified correctly)/(total # of tweets)\n",
    "    \"\"\"\n",
    "    accuracy = 0  # return this properly\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    y_hats = []\n",
    "    for comment in x_test:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(comment, logprior, loglikelihood) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = np.sum(np.abs(y_hats - y_test)) / len(y_test)\n",
    "\n",
    "    # Accuracy is 1 minus the error\n",
    "    accuracy = 1 - error\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "print(test_naive_bayes(x_test, y_test, logprior, loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Model Error Analysis ===\n",
      "\n",
      "Truth Predicted Tweet\n",
      "1\t0.00\tb'can i get views and subscribers for no reason'\n",
      "0\t1.00\tb'since when has katy perry had her own youtube channel'\n",
      "1\t0.00\tb'hi d we re twin melody year old twins we did some covers we did a cover of birthday by katy perry please just take second and watch it thanks merci gracias danke obrigado grazie lt xx have a nice day d'\n",
      "0\t1.00\tb'this comment is wrong'\n",
      "1\t0.00\tb'like this comment if you still jam out to this song after years'\n",
      "1\t0.00\tb'o peoples of the earth i have seen how you perform every form of evil at your leisure you cease not from reveling in that which i hate behold you murder the innocent day and night and plot evil against your neighbor you stand up for the rights of those who commit abomination and clap your hands as wickedness is celebrated openly in the streets o most perverse and abominable generation shall i not repay hear the word of the lord trumpetcallofgodonline co m'\n",
      "1\t0.00\tb'pleassssssssssssssss subscribeeeeeeeeee my channnnnnelll plzz'\n",
      "0\t1.00\tb'she named the tiger kitty purry no seriously she did check the video'\n",
      "0\t1.00\tb'br'\n",
      "0\t1.00\tb'if you are a person that loves real music you should listen to quot cruz supat quot br he is awesome as fuck just as eminem used to be'\n",
      "1\t0.00\tb'yea stil the best wk song ever br thumbs up of you think the same br'\n",
      "0\t1.00\tb'just came to check the view count'\n",
      "1\t0.00\tb'aslamu lykum from pakistan'\n",
      "0\t1.00\tb'a href http www youtube com watch v kq zr kcpj amp t m s a best part'\n",
      "1\t0.00\tb'top three shakira songs my choice br br waka waka it s time for africa br br can t remember to forget you br br empire br br like this comment if u like shakira'\n",
      "0\t1.00\tb'i am now going to voyage to the first comment tell my family i loved them'\n",
      "0\t1.00\tb'this song is about rape and cheating br br br br br br br br br br basically'\n",
      "0\t1.00\tb'new goal let s go for it'\n",
      "\n",
      "\n",
      "=== Random Forest Classifier Error Analysis ===\n",
      "\n",
      "Truth Predicted Tweet\n",
      "1\t0.00\tb'follow follow vaahidmustafic like like'\n",
      "0\t1.00\tb'since when has katy perry had her own youtube channel'\n",
      "0\t1.00\tb'this comment is wrong'\n",
      "1\t0.00\tb'like this comment if you still jam out to this song after years'\n",
      "1\t0.00\tb'o peoples of the earth i have seen how you perform every form of evil at your leisure you cease not from reveling in that which i hate behold you murder the innocent day and night and plot evil against your neighbor you stand up for the rights of those who commit abomination and clap your hands as wickedness is celebrated openly in the streets o most perverse and abominable generation shall i not repay hear the word of the lord trumpetcallofgodonline co m'\n",
      "1\t0.00\tb'pleassssssssssssssss subscribeeeeeeeeee my channnnnnelll plzz'\n",
      "0\t1.00\tb'she named the tiger kitty purry no seriously she did check the video'\n",
      "1\t0.00\tb'yea stil the best wk song ever br thumbs up of you think the same br'\n",
      "1\t0.00\tb'aslamu lykum from pakistan'\n",
      "0\t1.00\tb'a href http www youtube com watch v kq zr kcpj amp t m s a best part'\n",
      "1\t0.00\tb'top three shakira songs my choice br br waka waka it s time for africa br br can t remember to forget you br br empire br br like this comment if u like shakira'\n",
      "0\t1.00\tb'million likes xd even the subscribers not million xd'\n",
      "1\t0.00\tb'like and subscrib if you watch in'\n",
      "0\t1.00\tb'hey it s charlie from lost'\n",
      "0\t1.00\tb'new goal let s go for it'\n",
      "0\t1.00\tb'my honest opinion it s a very mediocre song nothing unique or special about her music lyrics or voice nothing memorable like billie jean or beat it before her millions of fans reply with hate comments i know this is a democracy and people are free to see what they want but then don t i have the right to express my opinion please don t reply with dumb comments lie if you don t like it don t watch it i just came here to see what s the buzz about million views and didn t like what i saw ok'\n",
      "\n",
      "\n",
      "=== Multi-Layer Perceptron Model Error Analysis ===\n",
      "\n",
      "Truth Predicted Tweet\n",
      "0\t1.00\tb'my son love so much'\n",
      "1\t0.00\tb'youtube comments in a nut shell br br first br club br skip to a href http www youtube com watch v kq zr kcpj amp t m s a and close your eyes br advertisements br like this comment for no reason br christianity arguements br other religious arguements br console wars br pcmasterace br trolls br quot how is there million views on the this video if theres online people on earth br complaints br pewdiepie fangirls br minecraft scrubs br r montageparodies br br br and any other shit'\n",
      "0\t1.00\tb'since when has katy perry had her own youtube channel'\n",
      "0\t1.00\tb'this comment is wrong'\n",
      "1\t0.00\tb'like this comment if you still jam out to this song after years'\n",
      "0\t1.00\tb'fave song'\n",
      "0\t1.00\tb'the last year of decent music'\n",
      "0\t1.00\tb'should not have paused the music this is a clip not a movie'\n",
      "0\t1.00\tb'if you pause at at the last millisecond you can see that that chick is about to laugh takes a few tries'\n",
      "1\t0.00\tb'check me out i m kyle i rap so yeah'\n",
      "0\t1.00\tb'katy is mine the girl of my dreams'\n",
      "1\t0.00\tb'yea stil the best wk song ever br thumbs up of you think the same br'\n",
      "1\t0.00\tb'i personally have never been in a abusive relationship i probably never will i don t hit women mom has my dad used to hit my mom before he left i can relate i m writing about one at the moment subscribe to hear it every fan counts'\n",
      "0\t1.00\tb'do you guys know there s a part two of this song d'\n",
      "1\t0.00\tb'aslamu lykum from pakistan'\n",
      "1\t0.00\tb'top three shakira songs my choice br br waka waka it s time for africa br br can t remember to forget you br br empire br br like this comment if u like shakira'\n",
      "0\t1.00\tb'i am now going to voyage to the first comment tell my family i loved them'\n",
      "0\t1.00\tb'eminem is idol for very people in espa a and mexico or latinoamerica'\n",
      "0\t1.00\tb'see it all human folly right'\n",
      "0\t1.00\tb'lol i dunno how this joke gets a lot of likes but whatever xd'\n",
      "0\t1.00\tb'damnnnnnnnn she is sexy o o'\n",
      "0\t1.00\tb'million likes xd even the subscribers not million xd'\n",
      "0\t1.00\tb'every time i watch this mv i just so so so glad that i live in a world that don t have to worry about running from a real human eating tiger'\n",
      "0\t1.00\tb'new goal let s go for it'\n",
      "\n",
      "\n",
      "=== Naive Bayes Model Error Analysis ===\n",
      "\n",
      "Truth Predicted Tweet\n",
      "1\t0.00\tb'subscribe me plzzzzzzz plzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz'\n",
      "0\t1.00\tb'katy perry is awesome'\n",
      "1\t0.00\tb'once you have started reading do not stop if you do not subscribe to me within one day you and you re entire family will die so if you want to stay alive subscribe right now'\n",
      "0\t1.00\tb'llikee'\n",
      "0\t1.00\tb'since when has katy perry had her own youtube channel'\n",
      "1\t0.00\tb'subscribe me and i requite'\n",
      "0\t1.00\tb'fantastic'\n",
      "1\t0.00\tb'my uncle said he will stop smoking if this comment gets likes please like this comment thanks'\n",
      "1\t0.00\tb'like this comment if you still jam out to this song after years'\n",
      "1\t0.00\tb'o peoples of the earth i have seen how you perform every form of evil at your leisure you cease not from reveling in that which i hate behold you murder the innocent day and night and plot evil against your neighbor you stand up for the rights of those who commit abomination and clap your hands as wickedness is celebrated openly in the streets o most perverse and abominable generation shall i not repay hear the word of the lord trumpetcallofgodonline co m'\n",
      "0\t1.00\tb'i like the music but is anyone listening to the lyrics'\n",
      "0\t1.00\tb'it s been back for quite a while now'\n",
      "1\t0.00\tb'pleassssssssssssssss subscribeeeeeeeeee my channnnnnelll plzz'\n",
      "0\t1.00\tb'the last year of decent music'\n",
      "0\t1.00\tb'i m here to check the views holy shit'\n",
      "0\t1.00\tb'br'\n",
      "0\t1.00\tb'lip synch is terrible'\n",
      "1\t0.00\tb'subscribe please'\n",
      "0\t1.00\tb'awesome'\n",
      "0\t1.00\tb'if you are a person that loves real music you should listen to quot cruz supat quot br he is awesome as fuck just as eminem used to be'\n",
      "1\t0.00\tb'yea stil the best wk song ever br thumbs up of you think the same br'\n",
      "1\t0.00\tb'if i get subscribers i will summon freddy mercury s ghost to whipe from the face of earth one direction and miley cirus'\n",
      "0\t1.00\tb'i liked br'\n",
      "1\t0.00\tb'listen check out andrew guasch crazy sick flow i m dope that s all there is too it if you like it subscribe if not ill be with aftermath of tde soon enough one love peace'\n",
      "1\t0.00\tb'i personally have never been in a abusive relationship i probably never will i don t hit women mom has my dad used to hit my mom before he left i can relate i m writing about one at the moment subscribe to hear it every fan counts'\n",
      "0\t1.00\tb'don t mind me i m just checking what the views are up to'\n",
      "0\t1.00\tb'boooobs'\n",
      "0\t1.00\tb'awesome'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1.00\tb'millioon dislikesssssssssssssssssssssssssssssssss'\n",
      "0\t1.00\tb'views'\n",
      "0\t1.00\tb'why so many disliked'\n",
      "0\t1.00\tb''\n",
      "1\t0.00\tb'check out daneja good girl'\n",
      "0\t1.00\tb'gooooood'\n",
      "1\t0.00\tb'if u love rihanna subscribe me'\n",
      "0\t1.00\tb'a href http www youtube com watch v kq zr kcpj amp t m s a best part'\n",
      "1\t0.00\tb'top three shakira songs my choice br br waka waka it s time for africa br br can t remember to forget you br br empire br br like this comment if u like shakira'\n",
      "0\t1.00\tb'th most viewed video i guess'\n",
      "1\t0.00\tb'i like this comment and do not kill p'\n",
      "0\t1.00\tb'views near'\n",
      "0\t1.00\tb'i am now going to voyage to the first comment tell my family i loved them'\n",
      "1\t0.00\tb'if i reach subscribers i will tazz my self and my friend'\n",
      "0\t1.00\tb'see it all human folly right'\n",
      "1\t0.00\tb'could spanish people understand this br br any way s i how you doing subscribe to me i brake things br br'\n",
      "0\t1.00\tb'roaaaaarrrrrr'\n",
      "0\t1.00\tb'this song is about rape and cheating br br br br br br br br br br basically'\n",
      "0\t1.00\tb'some classsic'\n",
      "0\t1.00\tb'new goal let s go for it'\n",
      "0\t1.00\tb'the great mother of the jungle sweet and natural i like her videos'\n"
     ]
    }
   ],
   "source": [
    "# Error analysis of the above models\n",
    "\n",
    "print('=== Logistic Regression Model Error Analysis ===\\n')\n",
    "print('Truth Predicted Tweet')\n",
    "for x, x_tfidf, y in zip(x_test, x_test_tfidf, y_test):\n",
    "    y_hat = model_LR.predict(x_tfidf)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
    "            word_tokenize(process_content(x))).encode('ascii', 'ignore')))\n",
    "        \n",
    "print('\\n\\n=== Random Forest Classifier Error Analysis ===\\n')\n",
    "print('Truth Predicted Tweet')\n",
    "for x, x_tfidf, y in zip(x_test, x_test_tfidf, y_test):\n",
    "    y_hat = model_RFC.predict(x_tfidf)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
    "            word_tokenize(process_content(x))).encode('ascii', 'ignore')))\n",
    "        \n",
    "print('\\n\\n=== Multi-Layer Perceptron Model Error Analysis ===\\n')\n",
    "print('Truth Predicted Tweet')\n",
    "for x, x_tfidf, y in zip(x_test, x_test_tfidf, y_test):\n",
    "    y_hat = model_NN.predict(x_tfidf)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
    "            word_tokenize(process_content(x))).encode('ascii', 'ignore')))\n",
    "\n",
    "print('\\n\\n=== Naive Bayes Model Error Analysis ===\\n')\n",
    "print('Truth Predicted Tweet')\n",
    "for x, y in zip(x_test, y_test):\n",
    "    y_hat = naive_bayes_predict(x, logprior, loglikelihood)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
    "            word_tokenize(process_content(x))).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
